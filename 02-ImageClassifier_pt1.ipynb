{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning using TensorFlow and Keras.\n",
    "\n",
    "## 2.- Image classifier (pt.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second tutorial we are going to try to make a **classifier of images** of dogs and cats. In this case, the **data set is not prepared** and needs to be accommodated to what is most optimal for use in a neural network. The images come in color and come in different shapes and sizes. **We will adjust these features** so that the model is solid and can classify correctly.\n",
    "\n",
    "The images of the **dataset will be downloaded** from the Microsoft website which you can find [here](https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import expanduser\n",
    "import cv2\n",
    "\n",
    "\n",
    "DATADIR = os.path.expanduser('~') + \"/Documents/datasets/PetImages\" # Get the home path (from each user)\n",
    "CATEGORIES = ['Dog', 'Cat']\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category) # Path to cats or dogs dir\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "        plt.imshow(img_array, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DATADIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we convert all the images to grayscale? Because this particular classifier does not require the use of color to segment a feature. This saves computation time. OpenCV does not follow the classical RGB architecture but BGR. If we print one of the images with `imshow` the result will be a little strange because of this change in the order of representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape: \" + str(img_array.shape) + \"\\n\")\n",
    "print(\"Data: \\n\\n\" + str(img_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the images in the dataset have **different shapes** (as can be seen with the `img_array.shape` directive), as in exercise 1, we are going to **normalize** the entire dataset. It will be a size that has a **balance** between **definition** and image recognition while **minimizing the size**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 50\n",
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "plt.imshow(new_array, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since **the dataset is not tagged**, in the same procedure where we resize each image, **we will tag each image**. We don't need the tags to be 'Dog' or 'Cat', we can use a number tag that will have the same functionality. We set 0 to be a dog and 1 to be a cat ;-)\n",
    "\n",
    "So, taking the first category, dog, you will go image by image resizing and setting the label 0 for each one of them. Then the same will be done with the images of cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) # Path to cats or dogs dir\n",
    "        class_num = CATEGORIES.index(category) # 0 will be a dog and 1 will be a cat\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) # Get original image\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))               # Resize image\n",
    "                training_data.append([new_array, class_num])                          # [img, label]\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            \n",
    "create_training_data()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to **mix our dataset**. Since there is a loop through each of the categories (in our case dogs and cats), we want to avoid that the net trains first with dogs and then with cats. Therefore, using the Python `shuffle` library we will **shake** the datasets so that the next input image is random (probability 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pack it into the variables that we're going to use right before we feed it into our neuronal network so that's going to be an empty list `X` and an empty list for `y`. In general, capital `X` is your **feature** set and lowercase `y` is your **labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = feature set, y = labels\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can't pass a list to the neuronal network** (at least for the time being, maybe in the future, Keras will allow it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)     # X \n",
    "    y.append(label)        # y is a list\n",
    "    \n",
    "# X has to be first numpy array so let's go ahead:\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "# -1 is hoy many features do we have (something like that).\n",
    "# Last 1 is greyscale, 3 is RGB (BGR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid having to readjust the images every time you want to run the practice, you can use the Python [Pickle](https://docs.python.org/3/library/pickle.html) library, which **allows us to store (serialize)** the information for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"models/X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"models/y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"models/X.pickle\", \"rb\")\n",
    "x = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part we will create the model and run the neural network to see how to classify each of the images. See you in the next part ;-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
